**Diego Spranger / diego.spranger@code.berlin / FS2020 / SE_25 Data Science**

**Preliminary analysis of an own project**

<span style="text-decoration:underline;">Abstract</span>

Coming up with an own project was by far the hardest of all 3 tasks, mainly due to the task of matching a meaningful (to me) problem, with available data and the potential of a solution/answer through data science. Knowing I wanted to do something related with my home country of El Salvador, the first step of finding a sufficiently good dataset was completed thanks to a rather large dataset on a wide range of indicators from the World Bank. Then after taking into consideration the available data, deciding to try and answer whether El Salvador’s economy is actually improving or declining. Finally putting all my recently acquired knowledge to practice with a clear view of what I had to work with, and what I was looking to produce with it. Firstly cleaning and preprocessing the dataset, to then apply methods for descriptive statistics and data visualization that would help answer the investigations main question. Making use of my notes from the datacamp courses and other external resources such as StackOverflow, I was able to reach satisfying results from a preliminary analysis.

<span style="text-decoration:underline;">Reflection Essay</span>

The preliminary analysis of an own project was meant to take it one step further from the previous ‘guided data projects’. However, quite simply eliminating the guidance from the equation brought some rather unexpected problems. Nevertheless, taking on this task allowed me to experience just what I needed to understand just a bit better the intricacies and processes of projects in data science. I set out to learn what it took to carry out an investigation from scratch, furthermore, to actually do it on my own and test my recently acquired knowledge on data science as a whole. An objective I believe I met by the end of this task, regardless of having struggled where I expected it the least. Mainly while trying to match a topic of interest (in this case my home country of El Salvador) with available data. Where I took much longer than I should have, to come up with a specific topic and question I could answer based on a very complete dataset of El Salvador from the World Bank. Until finally I came to ask whether ‘El Salvador’s economy is actually improving or declining’. Once the question and topic were set, the preliminary analysis itself was quite successful. Even though the methods implemented were relatively simple, cleaning the data beforehand, implementing said methods, and generating results from them fulfilled the purpose of the task to me.

Given that this task was meant to allow me to implement what I had learned previously, the only resources I needed were my notes from the datacamp courses. Since everything I could have wanted to do with or to the dataset at hand, was in said notes. Getting used to referring back to it was undoubtedly valuable for me, knowing that this would be an effective technique for me in the future too. At the same time of course, some very particular problems arose throughout the preliminary analysis, which were quickly solved through the appropriate google searches. One example being the rearrangement of the dataset in use from having indicators as rows to having them as columns, indexed by years. This process was surprisingly straightforward, and just supports the idea of how being familiar with the right methods can make a complicated sounding problem a rather easy one.

Personally, I feel I was limited by my inability to come up with a better question and topic to match an available dataset. The fact that other than the World Bank’s dataset, there’s very little data about El Salvador available didn’t help either. This in turn limited the methods I could think of to apply to the data I had. I am honestly unsure of the level of detail a preliminary analysis must have, but for myself, I would have preferred to be able to apply more methods to help prove or disprove my hypotheses. Regardless, I must say I feel confident exploring a dataset, cleaning and wrangling it, visualizing it, and deriving results from it. I found that having knowledge of the capabilities of pandas, matplotlib, and seaborn allowed me to see problems and potential solutions in a very different way than I did before this module. While even though I know I’m quite far from knowing the full potential of the aforementioned libraries, this task showed me how it's a matter of exploration and somewhat of trial and error. As one can and most probably will reach satisfying conclusions with their current knowledge until this is not enough, moment at which one will have to look for some other method of completing the task at hand.
